{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b15cb8e-8f76-426e-a70c-a571ef6e2ab2",
   "metadata": {},
   "source": [
    "# Personally Identifiable Information (PII) Data Anonymization\n",
    "\n",
    "Script by Aussie Frost.\n",
    "\n",
    "This script removes Personally Identifiable Information (PII) from a given csv.\n",
    "\n",
    "A project for [CAHOOTS](https://whitebirdclinic.org/cahoots/)\n",
    "\n",
    "Started 4/15/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30919b09-1553-4db4-b1fc-7a18e33edf8e",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Source A: Self-generated test dataset (see 'data_generation.ipynb')\\\n",
    "Source A: A pre-cleaned source given by the org (yet to receive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94703641-e28c-4996-a324-94e7d834bb5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preliminary imports\n",
    "\n",
    "Note that these are all of the libraries used to run this script. You will need to install each one to ensure the script will run best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ed570a9-4f4d-4215-8a8b-0b2a1e0bb486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import regex as re\n",
    "import csv\n",
    "\n",
    "# import natural language processing libraries\n",
    "import spacy\n",
    "\n",
    "# load the spacy nlp model\n",
    "# note must install: python -m spacy download en_core_web_trf\n",
    "nlp = spacy.load(\"en_core_web_sm\") # en_core_web_sm or en_core_web_trf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b93072d-70bb-49ec-b9fa-25d21d96b62e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import ssa_names.txt file\n",
    "This is an aggregated set of names registered at least five times in the SSA database from years 1880-2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "615a5af6-5143-4f4c-995b-6b4f4003e2a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import ssafirstnames_list.txt file as ssafirstnames_list and sort asc\n",
    "with open('data/resources/ssafirstnames_list/ssafirstnames_list.txt', 'r') as file:\n",
    "    ssafirstnames_list = file.read().split(',')\n",
    "ssafirstnames_list = np.sort(ssafirstnames_list)\n",
    "\n",
    "# import lanestreets_list.txt file as lanestreets_list and sort asc\n",
    "with open('data/resources/lanestreets_list/lanestreets_list.txt', 'r') as file:\n",
    "    lanestreets_list = file.read().split(',')\n",
    "lanestreets_list = np.sort(lanestreets_list)\n",
    "\n",
    "# import states_list.txt file as states_list and sort asc\n",
    "with open('data/resources/states_list/states_list.txt', 'r') as file:\n",
    "    states_list = file.read().split(',')\n",
    "states_list = np.sort(states_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc86e59-7817-4a2a-a8be-c8ddbcc4e98a",
   "metadata": {},
   "source": [
    "## Defining case narrative anonymizer script\n",
    "\n",
    "This section contains a script for anonymizing a case narrative dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0a351e-63f0-42b7-bd99-c5e4cd238029",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Method 1: RegEx String Replacement\n",
    "This method involves defining regular expression patterns, then deploying these RegEx methods to further anonymize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1941ff27-5d71-4216-a703-bd529caf0204",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define regex patterns\n",
    "phone_pattern = r\"\\(?\\b(\\d{3})\\)?[-.\\s]*(\\d{3})[-.\\s]*(\\d{4})\\b\"\n",
    "address_pattern = r\"\\b\\d+\\s(?:[A-Za-z]+\\s)*(?:St|Street|Rd|Road|Ave|Avenue|Blvd|Boulevard|Pl|Place|Lane|Ln|Drive|Dr|Court|Ct|Terrace|Ter|Way)[,.\\s]\"\n",
    "web_pattern = r'(https?:\\/\\/)?(?:www\\.)?[a-zA-Z0-9\\.-]+\\.[a-zA-Z]{2,}(?:\\/\\S*)?'\n",
    "ip_pattern = r\"\\b((?:\\d{1,3}\\.){3}\\d{1,3}|([0-9a-fA-F]{1,4}:){7,7}[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,7}:|:([0-9a-fA-F]{1,4}:){1,7}|::(?:[0-9a-fA-F]{1,4}:){0,5}[0-9a-fA-F]{1,4})\\b\"\n",
    "zip_pattern = r\"\\b\\d{5,}\\b\"\n",
    "date_pattern = r\"\\b(?:\\d{1,2}(st|nd|rd|th)?\\s?(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)|\\d{1,2}/\\d{1,2}/?\\d{2,4}|\\d{4}-\\d{2}-\\d{2})\\b\"\n",
    "month_pattern = \"\\b(Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:t(?:ember)?)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)\\b\"\n",
    "num_pattern = r\"\\b\\w*[\\d]+\\w*\\b\"\n",
    "prefix_pattern = r\"\\b(Dr|Dr\\.|Mr|Mr\\.|Mrs|Mrs\\.|Ms|Ms\\.|Miss|Miss\\.|Sir|Madam)\\b\"\n",
    "\n",
    "def regex_remover(text, address_rem, date_rem, web_rem, ip_rem, zip_rem, phone_rem, num_rem):\n",
    "    \n",
    "    # apply RegEx pattern for each target feature\n",
    "    text, address_rem = re.subn(address_pattern, \"ADDRESS\", text, flags=re.IGNORECASE)\n",
    "    text, zip_rem = re.subn(zip_pattern, \"ZIP\", text, flags=re.IGNORECASE)\n",
    "    text, date_rem = re.subn(date_pattern, \"DATE\", text, flags=re.IGNORECASE)\n",
    "    text, date_rem = re.subn(month_pattern, \"DATE\", text, flags=re.IGNORECASE)\n",
    "    text, web_rem = re.subn(web_pattern, \"WEBSITE\", text, flags=re.IGNORECASE)\n",
    "    text, ip_rem = re.subn(ip_pattern, \"IP\", text, flags=re.IGNORECASE)\n",
    "    text, phone_rem = re.subn(phone_pattern, \"PHONE\", text, flags=re.IGNORECASE)\n",
    "    text, num_rem = re.subn(num_pattern, \"NUMBER\", text, flags=re.IGNORECASE)\n",
    "    text, prefix_rem = re.subn(prefix_pattern, \"PREFIX\", text, flags=re.IGNORECASE)\n",
    "    \n",
    "    return text, address_rem, date_rem, web_rem, ip_rem, zip_rem, phone_rem, num_rem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4492f2d-080e-467a-b83b-1063f11108a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Method 2: Natural Language Processing and Named Entity Recognition with spaCy\n",
    "For NLP, I am using spaCy and the 'en_core_web_sm' pretrained model (see more [here](https://spacy.io/models/en#en_core_web_sm))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d95633-3da7-4402-8e99-29ecb421d877",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nlp_anonymize_text(text, name_rem, address_rem, date_rem):\n",
    "    \"\"\" nlp_anonymize_text(text)\n",
    "    \n",
    "    - this function deploys a spaCy NLP model and removes\n",
    "    target features that are found that are found\n",
    "    \"\"\"\n",
    "    \n",
    "    # process the text with the NLP model\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # replace all recognized names with 'NAME_REMOVED'\n",
    "    for ent in doc.ents:\n",
    "\n",
    "        # first check for addresses\n",
    "        if ent.label_ in [\"GPE\", \"LOC\", \"FAC\"]:\n",
    "            text = text.replace(ent.text, \"ADDRESS\")\n",
    "            address_rem += 1\n",
    "        # then check for names\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            text = text.replace(ent.text, \"NAME\")\n",
    "            name_rem += 1\n",
    "        # then check for dates\n",
    "        if ent.label_ == \"DATE\":\n",
    "            text = text.replace(ent.text, \"DATE\")\n",
    "            date_rem += 1\n",
    "            \n",
    "    return text, name_rem, address_rem, date_rem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b61a88-d701-4ef9-980e-b98bc472d0eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Method 3: Predefined Term Replacement\n",
    "\n",
    "The first part of this method uses an aggregated set of first names registered at least five times in the SSA database from years 1880 through 2022. We call this method last as it is the most distructive to the original database.\n",
    "\n",
    "Then, this method uses a set of states and their shorthand forms such that states can be caught and replaced.\n",
    "\n",
    "#### BETTER METHOD\n",
    "Using a decision tree such as [this](https://github.com/vigviswa/Named-Entity-Recognition-Using-Decision-Trees). Can speed up the process instead of using comparison for every single name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59c44c23-d927-48d1-add8-d727419560d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssa_name_remover(text, name_rem):\n",
    "    \"\"\"\n",
    "    Replaces names in the given text with 'NAME_REM', handling names case-insensitively.\n",
    "    \n",
    "    Args:\n",
    "    text (str): The input text that may contain names.\n",
    "    ssa_names (set): A set of names that should be anonymized, assumed to be in lower case.\n",
    "\n",
    "    Returns:\n",
    "    str: The anonymized text.\n",
    "    int: The count of names replaced.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare regex pattern for case-insensitive matching\n",
    "    pattern = r'\\b(' + '|'.join(map(re.escape, ssafirstnames_list)) + r')\\b'\n",
    "    regex = re.compile(pattern, re.IGNORECASE)\n",
    "    \n",
    "    # Function to replace and count each match\n",
    "    def replace_func(match):\n",
    "        nonlocal name_rem\n",
    "        name_rem += 1\n",
    "        return \"NAME\"\n",
    "    \n",
    "    # Replace occurrences of any names in the text using a regex substitution\n",
    "    text_anonymized = regex.sub(replace_func, text)\n",
    "    \n",
    "    return text_anonymized, name_rem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f71ae024-e974-4720-a240-9752e26194ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lanecounty_streets_remover(text, address_rem):\n",
    "    \"\"\"\n",
    "    Replaces names in the given text with 'ADDRESS', handling names case-insensitively.\n",
    "    \n",
    "    Args:\n",
    "    text (str): The input text that may contain names.\n",
    "    ssa_names (set): A set of names that should be anonymized, assumed to be in lower case.\n",
    "\n",
    "    Returns:\n",
    "    str: The anonymized text.\n",
    "    int: The count of names replaced.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare regex pattern for case-insensitive matching\n",
    "    pattern = r'\\b(' + '|'.join(map(re.escape, lanestreets_list)) + r')\\b'\n",
    "    regex = re.compile(pattern, re.IGNORECASE)\n",
    "    \n",
    "    # Function to replace and count each match\n",
    "    def replace_func(match):\n",
    "        nonlocal address_rem\n",
    "        address_rem += 1\n",
    "        return \"ADDRESS\"\n",
    "    \n",
    "    # Replace occurrences of any names in the text using a regex substitution\n",
    "    text_anonymized = regex.sub(replace_func, text)\n",
    "    \n",
    "    return text_anonymized, address_rem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73342672-8047-4982-af5a-17893e108496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_remover(text, address_rem):\n",
    "    \n",
    "    # Prepare regex pattern for case-insensitive matching\n",
    "    pattern = r'\\b(' + '|'.join(map(re.escape, states_list)) + r')\\b'\n",
    "    regex = re.compile(pattern, re.IGNORECASE)\n",
    "    \n",
    "    # Replace occurrences of any state names or abbreviations in the text\n",
    "    text_anonymized, count = regex.subn(\"ADDRESS\", text)\n",
    "    \n",
    "    return text_anonymized, address_rem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b1b937a-4c91-4442-ab9b-3a33eba99fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_removal(case, name_rem, address_rem):\n",
    "    \n",
    "    # call predefined term removal functions\n",
    "    case, name_rem = ssa_name_remover(case, name_rem)\n",
    "    case, address_rem = lanecounty_streets_remover(case, address_rem)\n",
    "    case, address_rem = state_remover(case, address_rem) \n",
    "    \n",
    "    return case, name_rem, address_rem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c20bd88-9a50-48b4-b238-b3eabcc120b0",
   "metadata": {},
   "source": [
    "### Define single case_anonymizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ed6bf7c-40df-4d99-93f4-ae9a6834c97d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define data_anonymizer\n",
    "def data_anonymizer(case):\n",
    "    \"\"\" narrative_anonymizer(case)\n",
    "    \n",
    "    this function takes in a dataset, in this case a case narrative\n",
    "    and returns an anonymized case, where any identifying information\n",
    "    is replaced with a FEATURENAME, where FEATURENAME is representative\n",
    "    of the type of information that was removed.\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize removal counters\n",
    "    name_rem1 = name_rem3 = phone_rem = web_rem = address_rem1 = address_rem3 = ip_rem = zip_rem = date_rem1 = date_rem3 = num_rem = 0\n",
    "    \n",
    "    # METHOD 1-- RegEx replacement:\n",
    "    case, address_rem1, date_rem1, web_rem, ip_rem, zip_rem, phone_rem, num_rem = regex_remover(\n",
    "        case, address_rem3, date_rem3, web_rem, ip_rem, zip_rem, phone_rem, num_rem)\n",
    "    \n",
    "    # METHOD 2-- natural language processing:\n",
    "    # use NLP to anonomize target features\n",
    "    case, name_rem2, address_rem2, date_rem2 = nlp_anonymize_text(case, name_rem1, address_rem1, date_rem1)\n",
    "    \n",
    "    # METHOD 3-- predefined term replacement:\n",
    "    #if name_rem1 < 2: # define thresh !!! import from ssa_names.ipynb\n",
    "    case, name_rem3, address_rem3 = term_removal(case, name_rem3, address_rem3)\n",
    "    \n",
    "    # combine results\n",
    "    name_rem = name_rem2 + name_rem3\n",
    "    address_rem = address_rem1 + address_rem2 + address_rem3\n",
    "    date_rem = date_rem1 + date_rem2\n",
    "        \n",
    "    return {\n",
    "        \"call_transcription\": case,\n",
    "        \"name_removed\": name_rem,\n",
    "        \"phone_removed\": phone_rem,\n",
    "        \"address_removed\": address_rem,\n",
    "        \"web_removed\": web_rem,\n",
    "        \"ip_removed\": ip_rem,\n",
    "        \"zip_removed\": zip_rem,\n",
    "        \"date_removed\": date_rem,\n",
    "        \"num_removed\": num_rem\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95a2706-f43a-448d-a949-e2aaa933be4c",
   "metadata": {},
   "source": [
    "## Function to run anonymizer on complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d7f916b-25cb-4fdc-ad84-22c313952a88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def anonymize_narratives(in_datapath, out_datapath, target_colname, seperator=','):\n",
    "    \"\"\" \n",
    "    anonymize_narratives(\n",
    "        in_datapath: a path to your raw data,\n",
    "        out_datapath: a path to your raw data\n",
    "        target_colname: name of column that contains text to be anonymized,\n",
    "        seperator (optional): the delimitor that separates the in_data\n",
    "    ):\n",
    "\n",
    "    This function takes a raw data path, then deploys our data anonomyzer\n",
    "    on the case narrative dataset, strips target features and stores \n",
    "    cleaned case narratives alongside metrics of how many\n",
    "    features were removed in an anonymized data csv.\n",
    "    \"\"\"\n",
    "    \n",
    "    # read main dataset into pd dataframe\n",
    "    data = pd.read_csv(in_datapath, sep=seperator)\n",
    "    \n",
    "    # apply data_anonomizer and get resulting columns as list\n",
    "    print(\"anonymizer script running!\")\n",
    "    anonymized = data[target_colname].apply(data_anonymizer).to_list()\n",
    "    print(\"anonymizer script finished!\")\n",
    "\n",
    "    # create our anonymized dataframe\n",
    "    anonymized_cols = pd.DataFrame(anonymized)\n",
    "    \n",
    "    # drop old target column (transcript) from original data\n",
    "    original_df = data.drop(columns=target_colname)\n",
    "    \n",
    "    # merge the two dataframes together\n",
    "    anonymized_data = original_df.join(anonymized_cols)\n",
    "\n",
    "    # finally, write data to csv\n",
    "    anonymized_data.to_csv(out_datapath, index=False)\n",
    "    print(\"anonymized csv created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431d54a7-8329-461c-8a29-522ae17b0af9",
   "metadata": {},
   "source": [
    "## Deploying the case anonymizer\n",
    "\n",
    "Deploying the case anonymizer is as easy as one line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "902d5281-b57a-46c6-869e-3b8a585e383f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anonymizer script running!\n",
      "anonymizer script finished!\n",
      "anonymized csv created!\n"
     ]
    }
   ],
   "source": [
    "# anonymize the narratives\n",
    "anonymize_narratives(\"../data/call_data.csv\", \"../output/call_data_anonymized.csv\", \"call_transcription\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c0c104bc-729f-465e-83f5-5dcd7da90059",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
